{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model Fitting in Python\n",
        "\n",
        "In this worksheet we are going to look at how we might use python to fit data\n",
        "models. Later we will look at machine learning, but for now we will concentrate\n",
        "on traditional approaches to model fitting.\n",
        "\n",
        "*Note: it is common to find snippets of code for a task. There are so many python libraries it is not feasible to know all of the different libraries and codes. This has given rise to a mode of programming where individuals look for answers of stack overflow etc. This is now common practice for data exploration in Python. It does raise questions about attribution however and certaintly this would be bad practive for safety critical software development.*\n",
        "\n",
        "Let's start with a quick reminder about straight lines.\n",
        "\n",
        "These are descibed with a simple equation.\n",
        "\n",
        "$y = mx + c$\n",
        "\n",
        "The code below shows a graph showing how $m$ says how much the line changes in the $y$ axis for every step in the $x$ axis. $c$ tells us the point on the $y$ axis where we cross when $x = 0$."
      ],
      "metadata": {
        "id": "edMGbtZqTEe5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrCBOhKVTBDP"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "x = np.array([-2,-1, 0, 1, 2, 3, 4, 5])\n",
        "y = 0.7*x + 3\n",
        "\n",
        "plt.plot(x, y, 'k')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Simple straight line (y = 0.7*x + 3)')\n",
        "plt.grid()\n",
        "plt.scatter(0,3,color='red', marker=\"o\", alpha=0.1, s=300)\n",
        "plt.scatter(0,3,color='black', marker=\"x\")\n",
        "plt.plot([0,1], [3,3], 'r')\n",
        "plt.plot([1,1], [3,3.7], 'r')\n",
        "\n",
        "plt.plot([-2,0],[3,3], color='blue', linestyle='--')\n",
        "plt.axvline(x = 0.0, color = 'blue', linestyle = '--')\n",
        "\n",
        "plt.text(1.2, 3.2, 'm = 0.7')\n",
        "\n",
        "\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# So if I'm given two points on the axis can we write a function to give us the values of m and c?\n",
        "\n",
        "\n",
        "def getline(x1, y1, x2, y2):\n",
        "  m = (y2 - y1)/(x2 - x1)\n",
        "  c = y1 - m*x1\n",
        "  return m, c\n",
        "\n",
        "# now let's test it.\n",
        "(m,c) = getline(0,3,1,3.7)\n",
        "print(m,c)\n",
        "\n",
        "# does this give you the answer your expect?"
      ],
      "metadata": {
        "id": "xhV4aMceUXHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate some data with noise\n",
        "\n",
        "x = np.arange(0.0, 5.0, 0.1)\n",
        "noise =  np.random.normal(0,0.5, size =len(x))\n",
        "y = 0.7*x + 3\n",
        "y = y+ noise"
      ],
      "metadata": {
        "id": "e4axnTaiW8xr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.vstack((x,y))\n",
        "data = data.T\n",
        "df = pd.DataFrame(data, columns=['x','y'])\n",
        "df.head()\n",
        "df.to_csv('noisy_line.csv')"
      ],
      "metadata": {
        "id": "rJyHm6sYfSJK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(x, y, color='black')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Straight line  data with noise')\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "7EtWtXWCfS0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('noisy_line.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "9L4feIP6fi90"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.plot.scatter(x='x', y='y')"
      ],
      "metadata": {
        "id": "Y5hraPvCiBjA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# now we have our data let's look at how we can use python to fit a straight line to it\n",
        "\n",
        "# First we need to estimate what type of model will fit. In this case we believe it's\n",
        "# a straight line, which we call 'linear' so we use a technique called linear regression\n",
        "# which will try to minimise the errors for every point.\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "\n",
        "# Then we simply call the fitting function.\n",
        "reg = LinearRegression().fit(df[['x']], df.y)\n",
        "\n",
        "# having run the fitting function we can now look at the results\n",
        "print(f\" m {reg.coef_}, c : {reg.intercept_}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "DAUHgjq0iEk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now we could use these coefficients directly, but let's make use of a function\n",
        "# that the regression package gives is. it's called predict.\n",
        "# Now the prediction function expects an array as the input and the easiest way\n",
        "# to do this is to create a data frame\n",
        "\n",
        "v= 6\n",
        "input_value = pd.DataFrame([v], columns=['x'])\n",
        "\n",
        "value_predicted = reg.predict(input_value)\n",
        "print(f\"For an input of {v} we value_predicted {value_predicted}\")"
      ],
      "metadata": {
        "id": "73qjJdVokf2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Given that we have a vector of x values alredy ...\n",
        "df[['x']].head(5)"
      ],
      "metadata": {
        "id": "Ap1bQ3GhlmB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# we can use this to see how good our fit was.\n",
        "\n",
        "plt.scatter(x, y, color='black')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Linear regression')\n",
        "plt.plot(x, reg.predict(df[['x']]), color='red')\n",
        "plt.grid()"
      ],
      "metadata": {
        "id": "hkNO31e8i9Ea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Polynomial fitting\n",
        "\n",
        "Having looked at straight lines we now turn our attention to fitting more complex functions."
      ],
      "metadata": {
        "id": "CuElW799vZvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "x = np.arange(0.0, 5.0, 0.1)\n",
        "noise =  np.random.normal(0,0.2, size =len(x))\n",
        "y = 0.7*x**2 - 1.2*x -1\n",
        "y += noise\n",
        "\n",
        "\n",
        "plt.scatter(x, y, color='black')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Data with noise')\n",
        "plt.grid()\n",
        "\n",
        "data = np.vstack((x,y))\n",
        "data = data.T\n",
        "df = pd.DataFrame(data, columns=['x','y'])\n",
        "df.head()\n",
        "df.to_csv('noisy_curve.csv')\n"
      ],
      "metadata": {
        "id": "2FDlkDHhi-1O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's try and fit a straight line to this.\n",
        "\n",
        "\n",
        "# Then we simply call the fitting function.\n",
        "reg = LinearRegression().fit(df[['x']], df.y)\n",
        "\n",
        "# having run the fitting function we can now look at the results\n",
        "print(f\" m {reg.coef_}, c : {reg.intercept_}\")\n",
        "\n",
        "\n",
        "plt.scatter(x, y, color='black')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Data with noise')\n",
        "plt.grid()\n",
        "plt.plot(x, reg.predict(df[['x']]), color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eC0fAm8lvyAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well that doesn't look great at the start or the end of the data."
      ],
      "metadata": {
        "id": "cW9LqLTfxDj4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# But we might be able to guess that this is a quadratic.\n",
        "# numpy gives us the option of fitting polynomials, so let's do that.\n",
        "\n",
        "mymodel = np.poly1d(np.polyfit(df.x, df.y, 2))\n",
        "\n",
        "plt.scatter(x, y, color='black')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Data with noise')\n",
        "plt.grid()\n",
        "plt.plot(x, mymodel(df[['x']]), color='red')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "45B82GfPw5BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# there are other multiple libraries to do the same job.\n",
        "# Here is an example that uses the sklearn library\n",
        "# don't worry about the deatil here, just note that there\n",
        "# are many ways to do the same thing in python\n",
        "\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "\n",
        "model = make_pipeline(PolynomialFeatures(2), LinearRegression())\n",
        "model.fit(df[['x']], df.y)\n",
        "\n",
        "plt.scatter(x, y, color='black')\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Data with noise')\n",
        "plt.grid()\n",
        "plt.plot(x, model.predict(df[['x']]), color='red')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "WI3am6xMQkv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I'm going to leave line fitting here, but the basic idea is\n",
        "# Think about what form of model is likely to work.\n",
        "#\n",
        "# 1. Find a library that supports model fitting of that form\n",
        "# 2. Provide it with the data\n",
        "# 3. Compare the predicted to the actual.\n",
        "# 4. Use it to predict new values\n",
        "# if the fit is poor then you (usually) have the wrong model or insufficient data"
      ],
      "metadata": {
        "id": "gPPWwYM8yZ97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modelling with multiple inputs\n",
        "\n",
        "So not all data is represented by a line in 2 dimensions. What happens if your function is some thing like\n",
        "\n",
        "$y = 2 *x_1 + 3*x_2 - 2*x_1*x_2$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Qr2RgmE7Ak5U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's create some data in this form\n",
        "# example taken from :\n",
        "# https://realpython.com/linear-regression-in-python/#:~:text=Multiple%20Linear%20Regression%20With%20scikit%2Dlearn,-You%20can%20implement&text=The%20main%20difference%20is%20that,have%20two%20or%20more%20columns.&text=In%20multiple%20linear%20regression%2C%20x,usually%20a%20one%2Ddimensional%20array.\n",
        "\n",
        "\n",
        "x1 = np.array([0,5,15,25,35,45,55,60])\n",
        "x2 = np.array([1,1,2,5,11,15,34,35])\n",
        "\n",
        "x = np.vstack((x1,x2))\n",
        "y= [4,5,20,14,32,22,38, 43]"
      ],
      "metadata": {
        "id": "xiKbo0uYAkWw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "ax.scatter(x[0,:], x[1,:], y )\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dbusMISKBXR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The function expects the x data to be two columns, not rows hence I use a transpose.\n",
        "# Try removing the transpose if you want to see the error message we get.print(f\"intercept: {model.intercept_}\")\n",
        "model = LinearRegression().fit(x.transpose(), y)\n"
      ],
      "metadata": {
        "id": "RtEhjDP4BblN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r_sq = model.score(x.transpose(), y)\n",
        "# coefficient of determination: 0 not predictive power, 1 perfectly correct.\n",
        "print(f\"coefficient of determination: {r_sq}\")\n",
        "print(f\"intercept: {model.intercept_}\")\n",
        "print(f\"slope: {model.coef_}\")"
      ],
      "metadata": {
        "id": "rmmXKcbYBzRh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.intercept_ + np.sum(model.coef_ * x.transpose(), axis=1)"
      ],
      "metadata": {
        "id": "Y_IM8VwIGV_p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "ax.scatter(x[0,:], x[1,:], y )\n",
        "ax.plot(x[0,:], x[1,:], y_pred )\n",
        "ax.view_init(elev=20., azim=10) # change thse values to change the 'camera' position\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1eRf-S_HGuqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that moving about 2 inputs works jsut as well but we will find it much harder to visualise!\n",
        "\n",
        "That's when metrics like coefficient of determination become more useful."
      ],
      "metadata": {
        "id": "MUUyXufzHiVf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Fitting parametric distributions"
      ],
      "metadata": {
        "id": "mAHA9FBpIAFN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# So what di I mean by a parametric distribution?\n",
        "\n",
        "import scipy.stats as stats\n",
        "import math\n",
        "\n",
        "mu = 0\n",
        "variance = 1\n",
        "sigma = math.sqrt(variance)\n",
        "x = np.linspace(mu - 3*sigma, mu + 3*sigma, 100)\n",
        "plt.plot(x, stats.norm.pdf(x, mu, sigma))\n",
        "plt.grid()\n",
        "plt.xlabel('value')\n",
        "plt.ylabel('probability')\n",
        "plt.title('Normal distribution')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t-zHKqeBHElK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice the parameters of the distribution are mu (or mean) and sigma (standard deviation or spread/scale)."
      ],
      "metadata": {
        "id": "NYfvl5lAIjBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# So if I have a set of samples I might want to work out the mean and spread.\n",
        "# I'm not going to go into how we determine if a set of data is Gaussian, but\n",
        "# be aware just like all other model fitting when we select our model it might be\n",
        "# wrong, we jsut hope it's useful."
      ],
      "metadata": {
        "id": "FvQrz2xIHh_N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Taken from : https://www.geeksforgeeks.org/python-gaussian-fit/\n",
        "\n",
        "from scipy.optimize import curve_fit\n",
        "\n",
        "xdata = [ -10.0, -9.0, -8.0, -7.0, -6.0, -5.0, -4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
        "ydata = [1.2, 4.2, 6.7, 8.3, 10.6, 11.7, 13.5, 14.5, 15.7, 16.1, 16.6, 16.0, 15.4, 14.4, 14.2, 12.7, 10.3, 8.6, 6.1, 3.9, 2.1]\n",
        "\n",
        "# Recast xdata and ydata into numpy arrays so we can use their handy features\n",
        "xdata = np.asarray(xdata)\n",
        "ydata = np.asarray(ydata)\n",
        "plt.plot(xdata, ydata, 'o')\n",
        "\n",
        "# Define the Gaussian function\n",
        "def Gauss(x, A, B):\n",
        "    y = A*np.exp(-1*B*x**2)\n",
        "    return y\n",
        "\n",
        "parameters, covariance = curve_fit(Gauss, xdata, ydata)\n",
        "\n",
        "fit_A = parameters[0]\n",
        "fit_B = parameters[1]\n",
        "\n",
        "fit_y = Gauss(xdata, fit_A, fit_B)\n",
        "plt.plot(xdata, ydata, 'o', label='data')\n",
        "plt.plot(xdata, fit_y, '-', label='fit')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "pDdbFiHgIxWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import curve_fit\n",
        "\n",
        "xdata = [ -10.0, -9.0, -8.0, -7.0, -6.0, -5.0, -4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0]\n",
        "ydata = [1.2, 4.2, 6.7, 8.3, 10.6, 11.7, 13.5, 14.5, 15.7, 16.1, 16.6, 16.0, 15.4, 14.4, 14.2, 12.7, 10.3, 8.6, 6.1, 3.9, 2.1]\n",
        "\n",
        "# Recast xdata and ydata into numpy arrays so we can use their handy features\n",
        "xdata = np.asarray(xdata)\n",
        "ydata = np.asarray(ydata)\n",
        "plt.plot(xdata, ydata, 'o')\n",
        "\n",
        "# Define the Gaussian function\n",
        "def Gauss(x, A, B):\n",
        "    y = A*np.exp(-1*B*x**2)\n",
        "    return y\n",
        "\n",
        "parameters, covariance = curve_fit(Gauss, xdata, ydata)\n",
        "\n",
        "fit_A = parameters[0]\n",
        "fit_B = parameters[1]\n",
        "\n",
        "fit_y = Gauss(xdata, fit_A, fit_B)\n",
        "plt.plot(xdata, ydata, 'o', label='data')\n",
        "plt.plot(xdata, fit_y, '-', label='fit')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "Io4bslqLJ3DI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "curve_fit?"
      ],
      "metadata": {
        "id": "G-ZvpBvOJ6t7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e3N1MkO8KGH7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}